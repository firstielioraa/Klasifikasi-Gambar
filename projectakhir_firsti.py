# -*- coding: utf-8 -*-
"""ProjectAkhir_Firsti.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17ztIeE2OKNw9GW6NfZClCKfQdHK4l8xS

**Proyek Akhir: Image Classification Model Deployment**

Oleh: Firsti Eliora
"""

!pip install opendatasets
import opendatasets as od
import pandas as pd
import os
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from keras.models import Sequential
from keras.layers import Conv2D, AveragePooling2D, Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import TensorBoard
from keras.callbacks import EarlyStopping, ModelCheckpoint

od.download(
    "https://www.kaggle.com/datasets/utkarshsaxenadn/car-vs-bike-classification-dataset"
)

base_dir = '/content/car-vs-bike-classification-dataset/Car-Bike-Dataset'
os.listdir(base_dir)

# Defining Bike and Car image training folder 
bike = os.path.join(base_dir, 'Bike')
car = os.path.join(base_dir, 'Car')

# Melihat jumlah dataset
print("Jumlah dataset bike :",len(os.listdir(bike)))
print("jumlah dataset car :",len(os.listdir(car)))

# Grouping data into Training Data and Validation Data
from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=90,
                    horizontal_flip=True,
                    vertical_flip=True,
                    validation_split = 0.2
                    )

# Data labeling using ImageDataGenerator by folder
train_generator = train_datagen.flow_from_directory(
        base_dir,               
        target_size=(150, 150),  # mengubah resolusi menjadi 150x150 pixel
        # menggunakan caterogical karena lebih dari karena kasus klasikfikasi 3 kelas
        class_mode='binary',
        shuffle=True,
        batch_size = 32,
        subset='training')

validation_generator = train_datagen.flow_from_directory(
        base_dir,
        target_size=(150, 150), # mengubah resolusi menjadi 150x150 pixel
        # menggunakan caterogical karena lebih dari karena kasus klasifikasi 3 kelas
        class_mode='binary',
        shuffle=True,
        batch_size = 32,
        subset='validation')

class myCallback(tf.keras.callbacks.Callback):
  # Define the correct function signature for on_epoch_end
  def on_epoch_end(self, epoch, logs={}):
    if ((logs.get('accuracy') > 0.90)):
      print("\nReached 90% accuracy so cancelling training!") 
      # Stop training once the above condition is met
      self.model.stop_training = True
callbacks = myCallback()

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(512, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

model.summary()

model.compile(loss='binary_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

# latih model dengan model.fit 
result = model.fit(
    train_generator,
    steps_per_epoch= 25,  # berapa batch yang akan dieksekusi pada setiap epoch
    epochs=100, # tambahkan epochs jika akurasi model belum optimal
    validation_data=
    validation_generator, # menampilkan akurasi pengujian data validasi
    validation_steps=5,  # berapa batch yang akan dieksekusi pada setiap epoch
    verbose=2, callbacks=[callbacks])

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)  
  print(fn)
  if classes[0][0]==1:
    print('Ini adalah Bike')
  else:
   print('Ini adalah Car')

classes

print(train_generator.class_indices)

plt.plot(result.history['accuracy'], label='Train Accuracy')
plt.plot(result.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Plot')
plt.ylabel('Accuracy Value')
plt.xlabel('Epoch') 
plt.legend(loc="lower right")
plt.show()

plt.plot(result.history['loss'], label='Train Loss')
plt.plot(result.history['val_loss'], label='Validation Loss')
plt.title('Loss Plot')
plt.ylabel('Loss Value')
plt.xlabel('Epoch')
plt.legend(loc="upper right")
plt.show()

#Convert to tf lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

#save 
with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)